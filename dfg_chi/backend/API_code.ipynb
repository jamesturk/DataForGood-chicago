{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Base URL for the ACS data\n",
    "base_url = \"https://api.census.gov/data/{year}/acs/acs5\"\n",
    "\n",
    "# Variables to fetch\n",
    "\n",
    "# Economics\n",
    "# Employment\n",
    "# Median Income\n",
    "# Mean Income\n",
    "\n",
    "# Housing\n",
    "\n",
    "# HouseRent\n",
    "#variables = {'main_agg_rent': \"NAME,B25060_001E\", 'sub_median_rent': \"NAME,B25058_001E\", \n",
    "             #'sub_lower_rent': \"NAME,B25057_001E\", 'sub_upper_rent': \"NAME,B25059_001E\"}\n",
    "# HouseholdType\n",
    "variables = {'main_household_total': \"NAME,B11001_001E\", 'sub_household_family': \"NAME,B11001_002EA\", \n",
    "             'sub_household_nonfamily': \"NAME,B11001_007E\"}\n",
    "\n",
    "\n",
    "\n",
    "# Location filters\n",
    "location = \"for=tract:*&in=state:17+county:031\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function-1\n",
    "\n",
    "def extract_info_from_filename(filename, ind_type):\n",
    "    # Assuming filename is something like 'main_2017.csv'\n",
    "    parts = filename.split('_')\n",
    "    if len(parts) > 1:\n",
    "        year_part = parts[-1]  # This would be '2017.csv'\n",
    "        year = year_part.split('.')[0]  # This splits '2017.csv' into '2017' and 'csv' and takes the first part\n",
    "        if ind_type == 'main':\n",
    "            indicator = filename[5:-9]\n",
    "        else:\n",
    "            indicator = filename[4:-9]\n",
    "        if year.isdigit():  # Check if 'year' is all digits\n",
    "            return (indicator, int(year))\n",
    "    return None, None\n",
    "\n",
    "\n",
    "all_dataframes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2015 for main_household_total has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Housing/HouseholdType/main/main_household_total_2015.csv\n",
      "Data for 2016 for main_household_total has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Housing/HouseholdType/main/main_household_total_2016.csv\n",
      "Data for 2017 for main_household_total has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Housing/HouseholdType/main/main_household_total_2017.csv\n",
      "Data for 2018 for main_household_total has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Housing/HouseholdType/main/main_household_total_2018.csv\n",
      "Data for 2019 for main_household_total has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Housing/HouseholdType/main/main_household_total_2019.csv\n",
      "Data for 2020 for main_household_total has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Housing/HouseholdType/main/main_household_total_2020.csv\n",
      "Data for 2021 for main_household_total has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Housing/HouseholdType/main/main_household_total_2021.csv\n",
      "Data for 2022 for main_household_total has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Housing/HouseholdType/main/main_household_total_2022.csv\n",
      "Data for 2015 for sub_household_family has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Housing/HouseholdType/sub/sub_household_family_2015.csv\n",
      "Data for 2016 for sub_household_family has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Housing/HouseholdType/sub/sub_household_family_2016.csv\n",
      "Data for 2017 for sub_household_family has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Housing/HouseholdType/sub/sub_household_family_2017.csv\n",
      "Data for 2018 for sub_household_family has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Housing/HouseholdType/sub/sub_household_family_2018.csv\n",
      "Data for 2019 for sub_household_family has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Housing/HouseholdType/sub/sub_household_family_2019.csv\n",
      "Data for 2020 for sub_household_family has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Housing/HouseholdType/sub/sub_household_family_2020.csv\n",
      "Data for 2021 for sub_household_family has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Housing/HouseholdType/sub/sub_household_family_2021.csv\n",
      "Data for 2022 for sub_household_family has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Housing/HouseholdType/sub/sub_household_family_2022.csv\n",
      "Data for 2015 for sub_household_nonfamily has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Housing/HouseholdType/sub/sub_household_nonfamily_2015.csv\n",
      "Data for 2016 for sub_household_nonfamily has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Housing/HouseholdType/sub/sub_household_nonfamily_2016.csv\n",
      "Data for 2017 for sub_household_nonfamily has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Housing/HouseholdType/sub/sub_household_nonfamily_2017.csv\n",
      "Data for 2018 for sub_household_nonfamily has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Housing/HouseholdType/sub/sub_household_nonfamily_2018.csv\n",
      "Data for 2019 for sub_household_nonfamily has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Housing/HouseholdType/sub/sub_household_nonfamily_2019.csv\n",
      "Data for 2020 for sub_household_nonfamily has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Housing/HouseholdType/sub/sub_household_nonfamily_2020.csv\n",
      "Data for 2021 for sub_household_nonfamily has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Housing/HouseholdType/sub/sub_household_nonfamily_2021.csv\n",
      "Data for 2022 for sub_household_nonfamily has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Housing/HouseholdType/sub/sub_household_nonfamily_2022.csv\n"
     ]
    }
   ],
   "source": [
    "# Process each year from 2015 to 2019\n",
    "for name, variable in variables.items():    \n",
    "\n",
    "    ind_type = name.split('_')[0]\n",
    "\n",
    "    for year in range(2015, 2023):\n",
    "        # Construct the URL for the current year\n",
    "        url = f\"{base_url.format(year=year)}?get={variable}&{location}\"\n",
    "\n",
    "        # Make the request\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "\n",
    "        current_dir = os.getcwd()\n",
    "\n",
    "        # relative path specifically for Contract Rent indicator\n",
    "        relative_path = os.path.join('data_downloaded', 'Housing', 'HouseholdType')\n",
    "\n",
    "        # Combine the current directory with the relative path\n",
    "        full_base_path = os.path.join(current_dir, relative_path)\n",
    "\n",
    "        # Specify the path to save the CSV file, one for each year\n",
    "        file_path = os.path.join(full_base_path, f'{ind_type}/{name}_{year}.csv')\n",
    "        \n",
    "        # Open a CSV file for writing for each year\n",
    "        with open(file_path, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "\n",
    "            # Write the data into the CSV file\n",
    "            writer.writerows(data)\n",
    "\n",
    "        print(f\"Data for {year} for {name} has been written to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggregate table saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/user/23071/ipykernel_825442/3313839892.py:46: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.iloc[:, 1] = pd.to_numeric(df.iloc[:, 1], errors='coerce').fillna(0).astype(int)\n",
      "/tmp/user/23071/ipykernel_825442/3313839892.py:46: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.iloc[:, 1] = pd.to_numeric(df.iloc[:, 1], errors='coerce').fillna(0).astype(int)\n",
      "/tmp/user/23071/ipykernel_825442/3313839892.py:46: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.iloc[:, 1] = pd.to_numeric(df.iloc[:, 1], errors='coerce').fillna(0).astype(int)\n",
      "/tmp/user/23071/ipykernel_825442/3313839892.py:46: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.iloc[:, 1] = pd.to_numeric(df.iloc[:, 1], errors='coerce').fillna(0).astype(int)\n",
      "/tmp/user/23071/ipykernel_825442/3313839892.py:46: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.iloc[:, 1] = pd.to_numeric(df.iloc[:, 1], errors='coerce').fillna(0).astype(int)\n",
      "/tmp/user/23071/ipykernel_825442/3313839892.py:46: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.iloc[:, 1] = pd.to_numeric(df.iloc[:, 1], errors='coerce').fillna(0).astype(int)\n",
      "/tmp/user/23071/ipykernel_825442/3313839892.py:46: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.iloc[:, 1] = pd.to_numeric(df.iloc[:, 1], errors='coerce').fillna(0).astype(int)\n",
      "/tmp/user/23071/ipykernel_825442/3313839892.py:46: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.iloc[:, 1] = pd.to_numeric(df.iloc[:, 1], errors='coerce').fillna(0).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub_aggregate table saved\n"
     ]
    }
   ],
   "source": [
    "for ind_type in ['main', 'sub']:\n",
    "    \n",
    "    short_dir = os.path.join(full_base_path, f'{ind_type}')\n",
    "\n",
    "    if ind_type == 'main':    \n",
    "        id_counter = 1\n",
    "        for filename in os.listdir(short_dir):\n",
    "            if filename.endswith('.csv'):\n",
    "                filepath = os.path.join(short_dir, filename)\n",
    "            \n",
    "                indicator_name, year = extract_info_from_filename(filename, ind_type)\n",
    "\n",
    "                if indicator_name and year:\n",
    "                    df = pd.read_csv(filepath)\n",
    "                    # Create a new DataFrame with the required columns\n",
    "                    new_df = pd.DataFrame({\n",
    "                        'id': range(id_counter, id_counter + len(df)),\n",
    "                        'indicator_id': [int(2)] * len(df),\n",
    "                        'census_tract_id': df['tract'].astype(int),\n",
    "                        'indicator_name': indicator_name,\n",
    "                        'year': int(year),\n",
    "                        'value': df.iloc[:, 1].fillna(0).astype(int)\n",
    "                    })\n",
    "                    \n",
    "                    all_dataframes.append(new_df)\n",
    "\n",
    "        # Concatenate all DataFrames\n",
    "        final_dataframe = pd.concat(all_dataframes)\n",
    "\n",
    "        # Save to a new CSV file\n",
    "        final_dataframe.to_csv(os.path.join(short_dir, 'Main_Agg.csv'), index = False)\n",
    "        print('aggregate table saved')\n",
    "\n",
    "    else:\n",
    "        all_sub_dataframes = []  # List to store each file's DataFrame\n",
    "        id_counter = 1  # Initialize counter for the id column\n",
    "\n",
    "        for filename in os.listdir(short_dir):\n",
    "            if filename.startswith('sub') and filename.endswith('.csv'):\n",
    "                filepath = os.path.join(short_dir, filename)\n",
    "                sub_indicator_name, year = extract_info_from_filename(filename, ind_type)\n",
    "        \n",
    "                if sub_indicator_name and year:\n",
    "                    df = pd.read_csv(filepath)\n",
    "                    df['tract'] = pd.to_numeric(df['tract'], errors='coerce').fillna(0).astype(int)\n",
    "                    df.iloc[:, 1] = pd.to_numeric(df.iloc[:, 1], errors='coerce').fillna(0).astype(int)\n",
    "            \n",
    "            # Create a new DataFrame with the required columns\n",
    "                    new_sub_df = pd.DataFrame({\n",
    "                        'id': range(id_counter, id_counter + len(df)),\n",
    "                        'indicator_id': [int(2)] * len(df),\n",
    "                        'census_tract_id': df['tract'].astype(int),\n",
    "                        'sub_group_indicator_name': sub_indicator_name,\n",
    "                        'year': int(year),\n",
    "                        'value': df.iloc[:, 1].fillna(0).astype(int)\n",
    "            })\n",
    "                    id_counter += len(df)  # Increment the id counter\n",
    "                    \n",
    "                    # Append this new DataFrame to the list\n",
    "                    all_sub_dataframes.append(new_sub_df)\n",
    "\n",
    "# Concatenate all DataFrames for 'sub' into one\n",
    "final_sub_dataframe = pd.concat(all_sub_dataframes, ignore_index=True)\n",
    "\n",
    "# Save to a new CSV file\n",
    "final_sub_dataframe.to_csv(os.path.join(short_dir, 'Sub_Agg.csv'), index=False)\n",
    "\n",
    "print('sub_aggregate table saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
