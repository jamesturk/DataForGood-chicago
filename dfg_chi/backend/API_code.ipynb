{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Base URL for the ACS data\n",
    "base_url = \"https://api.census.gov/data/{year}/acs/acs5\"\n",
    "subject_url = \"https://api.census.gov/data/{year}/acs/acs5/subject\"\n",
    "profile_url = \"https://api.census.gov/data/{year}/acs/acs5/profile\"\n",
    "\n",
    "# Places to change\n",
    "# (1) variables (2) relative path\n",
    "\n",
    "# Variables to fetch\n",
    "\n",
    "# Economics #\n",
    "\n",
    "# Median Income\n",
    "#variables = {'main_median_income': \"NAME,S1903_C03_001E\", 'sub_median_white': \"NAME,S1903_C03_002E\",\n",
    "             #'sub_median_black': \"NAME,S1903_C03_003E\", 'sub_median_ind_ala': \"NAME,S1903_C03_004E\",\n",
    "             #'sub_median_asia': \"NAME,S1903_C03_005E\", 'sub_median_hawai': \"NAME,S1903_C03_006E\",\n",
    "             #'sub_median_other': \"NAME,S1903_C03_007E\"  }\n",
    "\n",
    "# Mean Income\n",
    "#variables = {'main_mean_income': \"NAME,S1902_C03_019E\", 'sub_mean_white': \"NAME,S1902_C03_020E\",\n",
    "             #'sub_mean_black': \"NAME,S1902_C03_021E\", 'sub_mean_ind_ala': \"NAME,S1902_C03_022E\",\n",
    "             #'sub_mean_asia': \"NAME,S1902_C03_023E\", 'sub_mean_hawai': \"NAME,S1902_C03_024E\",\n",
    "             #'sub_mean_other': \"NAME,S1902_C03_025E\"}\n",
    "\n",
    "# Housing #\n",
    "\n",
    "# HouseRent\n",
    "# variables = {'main_agg_rent': \"NAME,B25060_001E\", 'sub_median_rent': \"NAME,B25058_001E\", \n",
    "             #'sub_lower_rent': \"NAME,B25057_001E\", 'sub_upper_rent': \"NAME,B25059_001E\"}\n",
    "# HouseholdType\n",
    "#variables = {'main_household_total': \"NAME,B11001_001E\", 'sub_household_family': \"NAME,B11001_002EA\", \n",
    "             #'sub_household_nonfamily': \"NAME,B11001_007E\"}\n",
    "\n",
    "\n",
    "# Education\n",
    "# median earning\n",
    "#variables = {'main_median_earning': \"NAME,S1501_C01_059E\", 'sub_less_high': \"NAME,S1501_C01_060E\",\n",
    "             #'sub_high': \"NAME,S1501_C01_061E\", 'sub_college': \"NAME,S1501_C01_062E\",\n",
    "             #'sub_bachelor': \"NAME,S1501_C01_063E\", 'sub_grad': \"NAME,S1501_C01_064E\"}\n",
    "\n",
    "# enrollment\n",
    "#variables = {'main_enroll': \"NAME,S1401_C01_001E\", 'sub_nursery': \"NAME,S1401_C01_002E\",\n",
    "             #'sub_kind_12': \"NAME,S1401_C01_003E\", 'sub_college': \"NAME,S1401_C01_008E\",\n",
    "             #'sub_grad': \"NAME,S1401_C01_009E\"}\n",
    "\n",
    "# Health #\n",
    "# Disability\n",
    "#variables = {'main_disability': \"NAME,S1810_C02_001E\", 'sub_hearing': \"NAME,S1810_C02_019E\",\n",
    "             #'sub_vision': \"NAME,S1810_C02_029E\", 'sub_cognitive': \"NAME,S1810_C02_039E\",\n",
    "             #'sub_ambulatory': \"NAME,S1810_C02_047E\", 'sub_self_care': \"NAME,S1810_C02_055E\",\n",
    "             #'sub_ind_living': \"NAME,S1810_C02_063E\"}\n",
    "\n",
    "# Insurance\n",
    "#variables = {'main_population': \"NAME,S2701_C01_001E\", 'sub_insured': \"NAME,S2701_C02_001E\",\n",
    "             #'sub_uninsured': \"NAME,S2701_C04_001E\"}\n",
    "\n",
    "# Population #\n",
    "# Races\n",
    "#variables = {'main_population': \"NAME,S2701_C01_001E\", 'sub_insured': \"NAME,S2701_C02_001E\",\n",
    "             #'sub_uninsured': \"NAME,S2701_C04_001E\"}\n",
    "\n",
    "#variables = {'main_population': \"NAME,DP05_0033E\", 'sub_pop_white': \"NAME,DP05_0037E\",\n",
    "             #'sub_pop_black': \"NAME,DP05_0038E\", 'sub_pop_ind_ala': \"NAME,DP05_0039E\",\n",
    "             #'sub_pop_asia': \"NAME,DP05_0044E\", 'sub_pop_hawai': \"NAME,DP05_0052E\",\n",
    "             #'sub_pop_other': \"NAME,DP05_0057E\", 'sub_pop_two': \"NAME,DP05_0058E\"}\n",
    "\n",
    "variables = {'main_median_age': \"NAME,B01002_001E\", 'sub_male_age': \"NAME,B01002_002E\",\n",
    "             'sub_female_age': \"NAME,B01002_003E\"}\n",
    "\n",
    "# Location filters\n",
    "location = \"for=tract:*&in=state:17+county:031\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function-1\n",
    "\n",
    "def extract_info_from_filename(filename, ind_type):\n",
    "    # Assuming filename is something like 'main_2017.csv'\n",
    "    parts = filename.split('_')\n",
    "    if len(parts) > 1:\n",
    "        year_part = parts[-1]  # This would be '2017.csv'\n",
    "        year = year_part.split('.')[0]  # This splits '2017.csv' into '2017' and 'csv' and takes the first part\n",
    "        if ind_type == 'main':\n",
    "            indicator = filename[5:-9]\n",
    "        else:\n",
    "            indicator = filename[4:-9]\n",
    "        if year.isdigit():  # Check if 'year' is all digits\n",
    "            return (indicator, int(year))\n",
    "    return None, None\n",
    "\n",
    "all_dataframes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2017 for main_median_age has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Population/MedianAge/main/main_median_age_2017.csv\n",
      "Data for 2018 for main_median_age has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Population/MedianAge/main/main_median_age_2018.csv\n",
      "Data for 2019 for main_median_age has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Population/MedianAge/main/main_median_age_2019.csv\n",
      "Data for 2020 for main_median_age has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Population/MedianAge/main/main_median_age_2020.csv\n",
      "Data for 2021 for main_median_age has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Population/MedianAge/main/main_median_age_2021.csv\n",
      "Data for 2022 for main_median_age has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Population/MedianAge/main/main_median_age_2022.csv\n",
      "Data for 2017 for sub_male_age has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Population/MedianAge/sub/sub_male_age_2017.csv\n",
      "Data for 2018 for sub_male_age has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Population/MedianAge/sub/sub_male_age_2018.csv\n",
      "Data for 2019 for sub_male_age has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Population/MedianAge/sub/sub_male_age_2019.csv\n",
      "Data for 2020 for sub_male_age has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Population/MedianAge/sub/sub_male_age_2020.csv\n",
      "Data for 2021 for sub_male_age has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Population/MedianAge/sub/sub_male_age_2021.csv\n",
      "Data for 2022 for sub_male_age has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Population/MedianAge/sub/sub_male_age_2022.csv\n",
      "Data for 2017 for sub_female_age has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Population/MedianAge/sub/sub_female_age_2017.csv\n",
      "Data for 2018 for sub_female_age has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Population/MedianAge/sub/sub_female_age_2018.csv\n",
      "Data for 2019 for sub_female_age has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Population/MedianAge/sub/sub_female_age_2019.csv\n",
      "Data for 2020 for sub_female_age has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Population/MedianAge/sub/sub_female_age_2020.csv\n",
      "Data for 2021 for sub_female_age has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Population/MedianAge/sub/sub_female_age_2021.csv\n",
      "Data for 2022 for sub_female_age has been written to /home/yujie0706/DataForGood-chicago/dfg_chi/backend/data_downloaded/Population/MedianAge/sub/sub_female_age_2022.csv\n"
     ]
    }
   ],
   "source": [
    "for name, variable in variables.items():    \n",
    "\n",
    "    ind_type = name.split('_')[0]\n",
    "\n",
    "    for year in range(2017, 2023):\n",
    "        # Construct the URL for the current year\n",
    "        if variable[5:][0] == 'B':    \n",
    "            url = f\"{base_url.format(year=year)}?get={variable}&{location}\"\n",
    "        elif variable[5:][0] == 'S':\n",
    "            url = f\"{subject_url.format(year=year)}?get={variable}&{location}\"\n",
    "        else:\n",
    "            url = f\"{profile_url.format(year=year)}?get={variable}&{location}\"\n",
    "            \n",
    "        # Make the request\n",
    "        response = requests.get(url)\n",
    "\n",
    "        data = response.json()\n",
    "\n",
    "        current_dir = os.getcwd()\n",
    "\n",
    "        # relative path specifically for Contract Rent indicator\n",
    "        relative_path = os.path.join('data_downloaded', 'Population', 'MedianAge')\n",
    "\n",
    "        # Combine the current directory with the relative path\n",
    "        full_base_path = os.path.join(current_dir, relative_path)\n",
    "\n",
    "        # Specify the path to save the CSV file, one for each year\n",
    "        file_path = os.path.join(full_base_path, f'{ind_type}/{name}_{year}.csv')\n",
    "        \n",
    "        # Open a CSV file for writing for each year\n",
    "        with open(file_path, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "\n",
    "            # Write the data into the CSV file\n",
    "            writer.writerows(data)\n",
    "\n",
    "        print(f\"Data for {year} for {name} has been written to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggregate table saved\n",
      "sub_aggregate table saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/user/23071/ipykernel_1487263/3922620109.py:51: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.iloc[:, 1] = pd.to_numeric(df.iloc[:, 1], errors='coerce').fillna(0).astype(int)\n",
      "/tmp/user/23071/ipykernel_1487263/3922620109.py:51: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.iloc[:, 1] = pd.to_numeric(df.iloc[:, 1], errors='coerce').fillna(0).astype(int)\n",
      "/tmp/user/23071/ipykernel_1487263/3922620109.py:51: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.iloc[:, 1] = pd.to_numeric(df.iloc[:, 1], errors='coerce').fillna(0).astype(int)\n",
      "/tmp/user/23071/ipykernel_1487263/3922620109.py:51: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.iloc[:, 1] = pd.to_numeric(df.iloc[:, 1], errors='coerce').fillna(0).astype(int)\n",
      "/tmp/user/23071/ipykernel_1487263/3922620109.py:51: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.iloc[:, 1] = pd.to_numeric(df.iloc[:, 1], errors='coerce').fillna(0).astype(int)\n",
      "/tmp/user/23071/ipykernel_1487263/3922620109.py:51: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.iloc[:, 1] = pd.to_numeric(df.iloc[:, 1], errors='coerce').fillna(0).astype(int)\n",
      "/tmp/user/23071/ipykernel_1487263/3922620109.py:51: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.iloc[:, 1] = pd.to_numeric(df.iloc[:, 1], errors='coerce').fillna(0).astype(int)\n",
      "/tmp/user/23071/ipykernel_1487263/3922620109.py:51: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.iloc[:, 1] = pd.to_numeric(df.iloc[:, 1], errors='coerce').fillna(0).astype(int)\n",
      "/tmp/user/23071/ipykernel_1487263/3922620109.py:51: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.iloc[:, 1] = pd.to_numeric(df.iloc[:, 1], errors='coerce').fillna(0).astype(int)\n",
      "/tmp/user/23071/ipykernel_1487263/3922620109.py:51: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.iloc[:, 1] = pd.to_numeric(df.iloc[:, 1], errors='coerce').fillna(0).astype(int)\n",
      "/tmp/user/23071/ipykernel_1487263/3922620109.py:51: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.iloc[:, 1] = pd.to_numeric(df.iloc[:, 1], errors='coerce').fillna(0).astype(int)\n",
      "/tmp/user/23071/ipykernel_1487263/3922620109.py:51: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.iloc[:, 1] = pd.to_numeric(df.iloc[:, 1], errors='coerce').fillna(0).astype(int)\n"
     ]
    }
   ],
   "source": [
    "for ind_type in ['main', 'sub']:\n",
    "    \n",
    "    short_dir = os.path.join(full_base_path, f'{ind_type}')\n",
    "\n",
    "    if ind_type == 'main':    \n",
    "\n",
    "        id_counter = 1\n",
    "\n",
    "        for filename in os.listdir(short_dir):\n",
    "\n",
    "            if filename.endswith('.csv'):\n",
    "\n",
    "                filepath = os.path.join(short_dir, filename)\n",
    "            \n",
    "                indicator_name, year = extract_info_from_filename(filename, ind_type)\n",
    "\n",
    "                if indicator_name and year:\n",
    "                    df = pd.read_csv(filepath)\n",
    "                    # Create a new DataFrame with the required columns\n",
    "                    new_df = pd.DataFrame({\n",
    "                        'id': range(id_counter, id_counter + len(df)),\n",
    "                        'indicator_id': [int(2)] * len(df),\n",
    "                        'census_tract_id': df['tract'].astype(int),\n",
    "                        'indicator_name': indicator_name,\n",
    "                        'year': int(year),\n",
    "                        'value': df.iloc[:, 1].fillna(0).astype(int)\n",
    "                    })\n",
    "                    \n",
    "                    all_dataframes.append(new_df)\n",
    "\n",
    "        # Concatenate all DataFrames\n",
    "        final_dataframe = pd.concat(all_dataframes)\n",
    "\n",
    "        # Save to a new CSV file\n",
    "        final_dataframe.to_csv(os.path.join(short_dir, 'Main_Agg.csv'), index = False)\n",
    "        print('aggregate table saved')\n",
    "\n",
    "    else:\n",
    "\n",
    "        all_sub_dataframes = []  # List to store each file's DataFrame\n",
    "        id_counter = 1  # Initialize counter for the id column\n",
    "\n",
    "        for filename in os.listdir(short_dir):\n",
    "            if filename.startswith('sub') and filename.endswith('.csv'):\n",
    "                filepath = os.path.join(short_dir, filename)\n",
    "                sub_indicator_name, year = extract_info_from_filename(filename, ind_type)\n",
    "        \n",
    "                if sub_indicator_name and year:\n",
    "                    df = pd.read_csv(filepath)\n",
    "                    df['tract'] = pd.to_numeric(df['tract'], errors='coerce').fillna(0).astype(int)\n",
    "                    df.iloc[:, 1] = pd.to_numeric(df.iloc[:, 1], errors='coerce').fillna(0).astype(int)\n",
    "            \n",
    "            # Create a new DataFrame with the required columns\n",
    "                    new_sub_df = pd.DataFrame({\n",
    "                        'id': range(id_counter, id_counter + len(df)),\n",
    "                        'indicator_id': [int(2)] * len(df),\n",
    "                        'census_tract_id': df['tract'].astype(int),\n",
    "                        'sub_group_indicator_name': sub_indicator_name,\n",
    "                        'year': int(year),\n",
    "                        'value': df.iloc[:, 1].fillna(0).astype(int)\n",
    "            })\n",
    "                    id_counter += len(df)  # Increment the id counter\n",
    "                    \n",
    "                    # Append this new DataFrame to the list\n",
    "                    all_sub_dataframes.append(new_sub_df)\n",
    "\n",
    "# Concatenate all DataFrames for 'sub' into one\n",
    "final_sub_dataframe = pd.concat(all_sub_dataframes, ignore_index=True)\n",
    "\n",
    "# Save to a new CSV file\n",
    "final_sub_dataframe.to_csv(os.path.join(short_dir, 'Sub_Agg.csv'), index=False)\n",
    "\n",
    "print('sub_aggregate table saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
