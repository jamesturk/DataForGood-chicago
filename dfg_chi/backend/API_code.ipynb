{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import csv\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from census import Census\n",
    "from us import states\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base URL for the ACS data\n",
    "base_url = \"https://api.census.gov/data/{year}/acs/acs5\"\n",
    "subject_url = \"https://api.census.gov/data/{year}/acs/acs5/subject\"\n",
    "profile_url = \"https://api.census.gov/data/{year}/acs/acs5/profile\"\n",
    "\n",
    "# Location filters\n",
    "location = \"for=tract:*&in=state:17+county:031\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Aggregate Rent Variable: NAME,B25060_001E\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON data from file\n",
    "with open('variables.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "main_agg_rent = data['variables']['Housing']['HouseRent']['main_agg_rent']\n",
    "print(\"Main Aggregate Rent Variable:\", main_agg_rent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function-1\n",
    "\n",
    "def extract_info_from_filename(filename, ind_type):\n",
    "    # Assuming filename is something like 'main_2017.csv'\n",
    "    parts = filename.split('_')\n",
    "    if len(parts) > 1:\n",
    "        year_part = parts[-1]  # This would be '2017.csv'\n",
    "        year = year_part.split('.')[0]  # This splits '2017.csv' into '2017' and 'csv' and takes the first part\n",
    "        if ind_type == 'main':\n",
    "            indicator = filename[5:-9]\n",
    "        else:\n",
    "            indicator = filename[4:-9]\n",
    "        if year.isdigit():  # Check if 'year' is all digits\n",
    "            return (indicator, int(year))\n",
    "    return None, None\n",
    "\n",
    "all_dataframes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.census.gov/data/2015/acs/acs1/subject?get=NAME,S1903_C03_001E&for=tract:*&in=state:17+county:031\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "[Errno Expecting value] error: unknown/unsupported geography heirarchy: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/requests/models.py:910\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 910\u001b[0m     \u001b[39mreturn\u001b[39;00m complexjson\u001b[39m.\u001b[39;49mloads(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtext, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    911\u001b[0m \u001b[39mexcept\u001b[39;00m JSONDecodeError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    912\u001b[0m     \u001b[39m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[1;32m    913\u001b[0m     \u001b[39m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/simplejson/__init__.py:518\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, use_decimal, **kw)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m encoding \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    515\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    516\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m use_decimal \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[0;32m--> 518\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[1;32m    519\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/simplejson/decoder.py:370\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w, _PY3)\u001b[0m\n\u001b[1;32m    369\u001b[0m     s \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(s, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding)\n\u001b[0;32m--> 370\u001b[0m obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s)\n\u001b[1;32m    371\u001b[0m end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/simplejson/decoder.py:400\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx, _w, _PY3)\u001b[0m\n\u001b[1;32m    399\u001b[0m         idx \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m3\u001b[39m\n\u001b[0;32m--> 400\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscan_once(s, idx\u001b[39m=\u001b[39;49m_w(s, idx)\u001b[39m.\u001b[39;49mend())\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/home/yujie0706/DataForGood-chicago/dfg_chi/backend/API_code.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Buchicago/home/yujie0706/DataForGood-chicago/dfg_chi/backend/API_code.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Make the request\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Buchicago/home/yujie0706/DataForGood-chicago/dfg_chi/backend/API_code.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(url)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Buchicago/home/yujie0706/DataForGood-chicago/dfg_chi/backend/API_code.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m data \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39;49mjson()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Buchicago/home/yujie0706/DataForGood-chicago/dfg_chi/backend/API_code.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m current_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetcwd()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Buchicago/home/yujie0706/DataForGood-chicago/dfg_chi/backend/API_code.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# relative path specifically for Contract Rent indicator\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/requests/models.py:917\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    915\u001b[0m     \u001b[39mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[39m.\u001b[39mmessage)\n\u001b[1;32m    916\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 917\u001b[0m     \u001b[39mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[39m.\u001b[39mmsg, e\u001b[39m.\u001b[39mdoc, e\u001b[39m.\u001b[39mpos)\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: [Errno Expecting value] error: unknown/unsupported geography heirarchy: 0"
     ]
    }
   ],
   "source": [
    "for name, variable in variables.items():    \n",
    "\n",
    "    ind_type = name.split('_')[0]\n",
    "\n",
    "    for year in range(2015, 2020):\n",
    "        # Construct the URL for the current year\n",
    "        if variable[5:][0] == 'B':    \n",
    "            url = f\"{base_url.format(year=year)}?get={variable}&{location}\"\n",
    "        elif variable[5:][0] == 'S':\n",
    "            url = f\"{subject_url.format(year=year)}?get={variable}&{location}\"\n",
    "            print(url)\n",
    "        else:\n",
    "            url = f\"{profile_url.format(year=year)}?get={variable}&{location}\"\n",
    "            \n",
    "        # Make the request\n",
    "        response = requests.get(url)\n",
    "\n",
    "        data = response.json()\n",
    "\n",
    "        current_dir = os.getcwd()\n",
    "\n",
    "        # relative path specifically for Contract Rent indicator\n",
    "        relative_path = os.path.join('data_downloaded', 'Economics', 'MedianIncome')\n",
    "\n",
    "        # Combine the current directory with the relative path\n",
    "        full_base_path = os.path.join(current_dir, relative_path)\n",
    "\n",
    "        # Specify the path to save the CSV file, one for each year\n",
    "        file_path = os.path.join(full_base_path, f'{ind_type}/{name}_{year}.csv')\n",
    "        \n",
    "        # Open a CSV file for writing for each year\n",
    "        with open(file_path, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "\n",
    "            # Write the data into the CSV file\n",
    "            writer.writerows(data)\n",
    "\n",
    "        print(f\"Data for {year} for {name} has been written to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggregate table saved\n",
      "sub_aggregate table saved\n"
     ]
    }
   ],
   "source": [
    "for ind_type in ['main', 'sub']:\n",
    "    \n",
    "    short_dir = os.path.join(full_base_path, f'{ind_type}')\n",
    "\n",
    "    if ind_type == 'main':    \n",
    "\n",
    "        id_counter = 1\n",
    "\n",
    "        for filename in os.listdir(short_dir):\n",
    "\n",
    "            if filename.endswith('.csv'):\n",
    "\n",
    "                filepath = os.path.join(short_dir, filename)\n",
    "            \n",
    "                indicator_name, year = extract_info_from_filename(filename, ind_type)\n",
    "\n",
    "                if indicator_name and year:\n",
    "                    df = pd.read_csv(filepath)\n",
    "                    # Create a new DataFrame with the required columns\n",
    "                    new_df = pd.DataFrame({\n",
    "                        'id': range(id_counter, id_counter + len(df)),\n",
    "                        'indicator_id': [int(2)] * len(df),\n",
    "                        'census_tract_id': df['tract'].astype(int),\n",
    "                        'indicator_name': indicator_name,\n",
    "                        'year': int(year),\n",
    "                        'value': df.iloc[:, 1].fillna(0).astype(int)\n",
    "                    })\n",
    "                    \n",
    "                    all_dataframes.append(new_df)\n",
    "\n",
    "        # Concatenate all DataFrames\n",
    "        final_dataframe = pd.concat(all_dataframes)\n",
    "\n",
    "        # Save to a new CSV file\n",
    "        final_dataframe.to_csv(os.path.join(short_dir, 'Main_Agg.csv'), index = False)\n",
    "        print('aggregate table saved')\n",
    "\n",
    "    else:\n",
    "\n",
    "        all_sub_dataframes = []  # List to store each file's DataFrame\n",
    "        id_counter = 1  # Initialize counter for the id column\n",
    "\n",
    "        for filename in os.listdir(short_dir):\n",
    "            if filename.startswith('sub') and filename.endswith('.csv'):\n",
    "                filepath = os.path.join(short_dir, filename)\n",
    "                sub_indicator_name, year = extract_info_from_filename(filename, ind_type)\n",
    "        \n",
    "                if sub_indicator_name and year:\n",
    "                    df = pd.read_csv(filepath)\n",
    "                    df['tract'] = pd.to_numeric(df['tract'], errors='coerce').fillna(0).astype(int)\n",
    "                    df.iloc[:, 1] = pd.to_numeric(df.iloc[:, 1], errors='coerce').fillna(0).astype(int)\n",
    "            \n",
    "            # Create a new DataFrame with the required columns\n",
    "                    new_sub_df = pd.DataFrame({\n",
    "                        'id': range(id_counter, id_counter + len(df)),\n",
    "                        'indicator_id': [int(2)] * len(df),\n",
    "                        'census_tract_id': df['tract'].astype(int),\n",
    "                        'sub_group_indicator_name': sub_indicator_name,\n",
    "                        'year': int(year),\n",
    "                        'value': df.iloc[:, 1].fillna(0).astype(int)\n",
    "            })\n",
    "                    id_counter += len(df)  # Increment the id counter\n",
    "                    \n",
    "                    # Append this new DataFrame to the list\n",
    "                    all_sub_dataframes.append(new_sub_df)\n",
    "\n",
    "# Concatenate all DataFrames for 'sub' into one\n",
    "final_sub_dataframe = pd.concat(all_sub_dataframes, ignore_index=True)\n",
    "\n",
    "# Save to a new CSV file\n",
    "final_sub_dataframe.to_csv(os.path.join(short_dir, 'Sub_Agg.csv'), index=False)\n",
    "\n",
    "print('sub_aggregate table saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
